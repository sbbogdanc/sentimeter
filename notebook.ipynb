{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18ebbd838e32"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16f0f41c2f9c"
   },
   "source": [
    "# Sentiment Analysis Model on Vertex AI with Hugging Face ðŸ¤—"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4339ebfdf7a0"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This project showcases building and deploying a text sentiment classification model. The model is developed by finetuning [BERT][bert], a popular NLP foundational model from [Hugging Face][hf]. To facilitate model development, deployment, and management, the project leverages various services including [Vertex AI][vertex], [Pytorch SDK][pytorch], [Artifact Registry][ar], [Cloud Build][cb], [Cloud Deploy][cd] and [Cloud Storage][cs]. \n",
    "\n",
    "[bert]: https://huggingface.co/bert-base-cased\n",
    "[hf]: https://huggingface.co/\n",
    "[vertex]: https://cloud.google.com/vertex-ai\n",
    "[ar]: https://cloud.google.com/artifact-registry\n",
    "[cb]: https://cloud.google.com/build\n",
    "[cd]: https://cloud.google.com/deploy\n",
    "[cs]: https://cloud.google.com/storage\n",
    "[pytorch]: https://pytorch.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9283a2954aef"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this tutorial, you learn to build, train, tune and deploy a PyTorch model on [Vertex AI](https://cloud.google.com/vertex-ai). You mainly focus on support for custom model training and deployment on Vertex AI. \n",
    "\n",
    "\n",
    "This tutorial uses the following Google Cloud services:\n",
    "\n",
    "- MLOps\n",
    "  - Vertex AI Workbench\n",
    "  - Vertex AI Training\n",
    "  - Vertex AI Model Registry\n",
    "  - Vertex AI Predictions\n",
    "- DevOps\n",
    "  - Cloud Build\n",
    "  - Cloud Deploy\n",
    "  - Artifact Registry\n",
    "  - Cloud Storage\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- Create training package for the text classification model.\n",
    "- Train the model with custom training on Vertex AI.\n",
    "- Check the created model artifacts.\n",
    "- Create a custom container for predictions.\n",
    "- Deploy the trained model to a Vertex AI Endpoint using the custom container for predictions.\n",
    "- Send online prediction requests to the deployed model and validate.\n",
    "- Clean up the resources created in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ab69c72f7c47"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset used for this tutorial is the [Happy Moments](https://www.kaggle.com/ritresearch/happydb) dataset from Kaggle. Learn more about the dataset in [HappyDB](https://rit-public.github.io/HappyDB/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "181d4dfbf917"
   },
   "source": [
    "### Costs \n",
    "\n",
    "Learn about pricing for [Vertex AI](https://cloud.google.com/vertex-ai/pricing), [Cloud Storage](https://cloud.google.com/storage/pricing), [Cloud Build](https://cloud.google.com/build/pricing), [Cloud Deploy](https://cloud.google.com/deploy/pricing) and [Artifact Registry](https://cloud.google.com/artifact-registry/pricing). Use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3848df1e5b0"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Install the packages required for executing this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install google-cloud-aiplatform accelerate transformers --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "#### Set your project ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you know your project ID, update the `PROJECT_ID` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"<your_project_id>\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, get the project ID using gcloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "    PROJECT_ID == \"\"\n",
    "    or PROJECT_ID is None \n",
    "    or PROJECT_ID == \"<your_project_id>\"\n",
    "):\n",
    "    import google.auth\n",
    "\n",
    "    _, PROJECT_ID = google.auth.default()\n",
    "    print(\"Project ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the project ID in your active configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### Set the region\n",
    "\n",
    "Set the `REGION` variable; it defaults to `\"us-central1\"`. Learn more about Vertex AI [regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nsN5NJKSu-GU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b45b2839f8b9"
   },
   "source": [
    "#### UUID\n",
    "\n",
    "To avoid name collisions, generate a UUID and append it to resources created in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "e80050370d51",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "UUID = generate_uuid()\n",
    "print(\"UUID: \", UUID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "Create a storage bucket to store intermediate artifacts such as datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MzGDU7TWdts_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://sentimeter-ml-artifacts-{UUID}\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "Create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d0f7629c309"
   },
   "source": [
    "### Import libraries and define constants\n",
    "\n",
    "Import the required libraries for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "528bfbda0197",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import accelerate\n",
    "import transformers\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf.json_format import MessageToDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "290fd65fc20c"
   },
   "source": [
    "Define the constants needed for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9022ff0e121b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Name for the package application / model / repository\n",
    "APP_NAME = \"finetuned-bert-classifier\"\n",
    "\n",
    "# URI for the pre-built container for custom training\n",
    "PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.1-11:latest\"\n",
    ")\n",
    "\n",
    "# Name of the folder where the python package needs to be stored\n",
    "PYTHON_PACKAGE_APPLICATION_DIR = \"pkg\"\n",
    "\n",
    "# Path to the source distribution tar of the python package\n",
    "SOURCE_PACKAGE_FILE_NAME = f\"{PYTHON_PACKAGE_APPLICATION_DIR}/dist/trainer-0.1.tar.gz\"\n",
    "\n",
    "# GCS path where the python package is stored\n",
    "PYTHON_PACKAGE_GCS_URI = (\n",
    "    f\"{BUCKET_URI}/pytorch-on-gcp/{APP_NAME}/train/python_package/trainer-0.1.tar.gz\"\n",
    ")\n",
    "\n",
    "# Module name for training application\n",
    "PYTHON_MODULE_NAME = \"trainer.task\"\n",
    "\n",
    "# Training job's display name\n",
    "JOB_NAME = f\"{APP_NAME}-pytorch-pkg-train-{UUID}\"\n",
    "\n",
    "# Set training job's machine-type\n",
    "TRAIN_MACHINE_TYPE = \"n1-standard-8\"\n",
    "\n",
    "# Training job's accelerator type\n",
    "# One of _ACCELERATOR_TYPE_UNSPECIFIED_, _NVIDIA_TESLA_K80_, _NVIDIA_TESLA_P100_, \n",
    "# _NVIDIA_TESLA_V100_, _NVIDIA_TESLA_P4_, _NVIDIA_TESLA_T4_, _NVIDIA_TELSA_A100_\n",
    "TRAIN_ACCELERATOR_TYPE = \"NVIDIA_TESLA_V100\"\n",
    "\n",
    "# The number of accelerators to attach to a worker replica for the training job\n",
    "TRAIN_ACCELERATOR_COUNT = 1\n",
    "\n",
    "# The number of worker replicas\n",
    "REPLICA_COUNT = 1\n",
    "\n",
    "TRAINING_ARGS = [\"--num-epochs\", \"2\", \"--model-name\", APP_NAME]\n",
    "\n",
    "# The name of the container image for prediction\n",
    "CUSTOM_PREDICTOR_IMAGE_URI = (\n",
    "    f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{APP_NAME}/pytorch_predict_{APP_NAME}:latest\"\n",
    ")\n",
    "\n",
    "# The version for model-deployment\n",
    "VERSION = 1\n",
    "\n",
    "# The model display name and id\n",
    "MODEL_DISPLAY_NAME = f\"{APP_NAME}-v{VERSION}\"\n",
    "MODEL_ID = f\"{APP_NAME}-v{VERSION}\"\n",
    "\n",
    "# The model description\n",
    "MODEL_DESCRIPTION = \"PyTorch based text classifier with custom container\"\n",
    "\n",
    "# The health route for prediction container\n",
    "HEALTH_ROUTE = \"/ping\"\n",
    "\n",
    "# The predict route for prediction container\n",
    "PREDICT_ROUTE = f\"/predictions/{APP_NAME}\"\n",
    "\n",
    "# The serving container ports for prediction\n",
    "SERVING_CONTAINER_PORTS = [7080]\n",
    "\n",
    "# The display name for endpoint\n",
    "ENDPOINT_DISPLAY_NAME = f\"{APP_NAME}-endpoint\"\n",
    "\n",
    "# The machine-type for deployment\n",
    "DEPLOY_MACHINE_TYPE = \"n1-standard-4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d31e7ad1192"
   },
   "source": [
    "### Initialize the Vertex AI SDK for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0d689f14d93c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d52388cb4fd"
   },
   "source": [
    "## Custom Training on Vertex AI\n",
    "\n",
    "The `pkg` directory structure uses the packaging approach [recommended](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container#structure) by Vertex AI.\n",
    "\n",
    "* The main directory contains a `setup.py` file with the required dependencies.\n",
    "* The `trainer` directory contains:\n",
    "  * `experiment.py` - Runs the model training and evaluation experiment, and exports the final model.\n",
    "  * `metadata.py` - Defines the metadata for classification tasks such as predefined model, dataset name and target labels.\n",
    "  * `model.py` -  Includes a function to create a model with a sequence classification head from a pre-trained model.\n",
    "  * `task.py` - Main application module initializes and parse task arguments and hyperparameters. It also serves as an entry point to the trainer.\n",
    "  * `utils.py` - Includes utility functions such as those used for reading data, saving models to Cloud Storage buckets.\n",
    "  * `__init__.py` - Indicates to [Python Setuptools](https://setuptools.readthedocs.io/en/latest/) to include all subdirectories of the parent directory as dependencies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cf62c83bdcbc"
   },
   "source": [
    "Create a source distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11d1299bcc12",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cd {PYTHON_PACKAGE_APPLICATION_DIR} && python3 setup.py sdist --formats=gztar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e61169bcd7a"
   },
   "source": [
    "Upload the source distribution with the training application to Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bff74cab1888",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! gsutil cp {SOURCE_PACKAGE_FILE_NAME} {PYTHON_PACKAGE_GCS_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3d00f9beaba7"
   },
   "source": [
    "Validate that the source distribution exists in the Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "376bc46aa1e0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! gsutil ls -l {PYTHON_PACKAGE_GCS_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88e4fd6394a0"
   },
   "source": [
    "### Run a custom job in Vertex AI using a pre-built container \n",
    "\n",
    "You don't need to build a PyTorch environment from scratch for running the training application because Vertex AI provides [pre-built containers](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers#available_container_images) which are Docker container images that you can use for custom training. They include some common dependencies used in training code based on the machine learning framework and framework version. Learn more about [CustomPythonPackageTrainingJob](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomPythonPackageTrainingJob) which is used to launch a Custom Training Job in Vertex AI using a Python package.\n",
    "\n",
    "Configure a [Custom Job](https://cloud.google.com/vertex-ai/docs/training/create-custom-job) with the [pre-built container for PyTorch](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers#pytorch) and training code packaged as Python source distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "c87d5618d366",
    "tags": []
   },
   "outputs": [],
   "source": [
    "job = aiplatform.CustomPythonPackageTrainingJob(\n",
    "    display_name=JOB_NAME,\n",
    "    python_package_gcs_uri=PYTHON_PACKAGE_GCS_URI,\n",
    "    python_module_name=PYTHON_MODULE_NAME,\n",
    "    container_uri=PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfe709ea0a2f"
   },
   "source": [
    "Run the Custom training job. Note that the training may take over 24 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8ac1bcb31a7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = job.run(\n",
    "    replica_count=REPLICA_COUNT,\n",
    "    machine_type=TRAIN_MACHINE_TYPE,\n",
    "    accelerator_type=TRAIN_ACCELERATOR_TYPE,\n",
    "    accelerator_count=TRAIN_ACCELERATOR_COUNT,\n",
    "    args=TRAINING_ARGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d0f5ea96675"
   },
   "source": [
    "Validate that the model artifacts are written to Cloud Storage by the training code after the job completes successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "502123b87fa3"
   },
   "outputs": [],
   "source": [
    "job_response = MessageToDict(job._gca_resource._pb)\n",
    "GCS_MODEL_ARTIFACTS_URI = job_response[\"trainingTaskInputs\"][\"baseOutputDirectory\"][\"outputUriPrefix\"]\n",
    "print(f\"Model artifacts are available at {GCS_MODEL_ARTIFACTS_URI}\")\n",
    "\n",
    "! gsutil ls -lr $GCS_MODEL_ARTIFACTS_URI/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9caf6a802e99"
   },
   "source": [
    "## Deployment\n",
    "\n",
    "Deploying a PyTorch [model on Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/getting-predictions) requires a custom container that serves online predictions on a Vertex AI Endpoint. Deploy a container running [PyTorch's TorchServe](https://pytorch.org/serve/) tool in order to serve predictions from the fine-tuned transformer model for a sentiment analysis task. Then, use Vertex AI's online prediction service to classify the sentiment of input texts. Learn more in the deployment [docs](docs/deployment.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6f0026a985fa"
   },
   "source": [
    "### Create a custom container image to serve predictions\n",
    "\n",
    "Use [Cloud Build](https://cloud.google.com/build) to create the custom container image and store it in [Artifact Registry](https://cloud.google.com/artifact-registry)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86b272c76889"
   },
   "source": [
    "#### Download the model artifacts from GCS to local directory\n",
    "\n",
    "First, validate that model artifact files exist in the Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0d160b2911ac"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -r $GCS_MODEL_ARTIFACTS_URI/model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38d171b3eb23"
   },
   "source": [
    "Then, copy the files from Cloud Storage to a local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9138f330c9f2"
   },
   "outputs": [],
   "source": [
    "! gsutil -m cp -r $GCS_MODEL_ARTIFACTS_URI/model/ ./predictor/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, validate that the model artifacts were copied to the local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2f9c5a82b1ed"
   },
   "outputs": [],
   "source": [
    "! ls -ltrR ./predictor/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ec61feb1188"
   },
   "source": [
    "#### Dockerfile for the image\n",
    "\n",
    "The [Dockerfile](predictor/Dockerfile) is based on the TorchServe and performs several steps:\n",
    "\n",
    " - Install dependencies.\n",
    " - Add model artifacts.\n",
    " - Add the custom handler script.\n",
    " - Define the serving configuration e.g. health and prediction listener ports.\n",
    " - Run the Torch model archiver to create a model archive file from the files copied into in the container image.\n",
    " - Launch TorchServe HTTP server, which references the configuration properties and allows serving for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the `APP_NAME` variable in the `Dockerfile` with the value specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6602ec14439c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! sed -i- \"s/\\$APP_NAME/${APP_NAME}/g\" \"Dockerfile\" && rm Dockerfile-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d3993843108"
   },
   "source": [
    "#### Create a docker repository in Artifact Registry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new Docker repository in Artifact Registry with your specified region and description. Set `APP_NAME` as the name of the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud artifacts repositories create {APP_NAME} \\\n",
    "    --repository-format=docker \\\n",
    "    --location={REGION} \\\n",
    "    --description=\"Docker repo for ML\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all Artifact Registry repositories and check for the new repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd1c0a3fbcdb"
   },
   "outputs": [],
   "source": [
    "! gcloud artifacts repositories list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4601a036e327"
   },
   "source": [
    "#### Build the docker image using Cloud Build\n",
    "\n",
    "Build a docker image inside the created repository using Cloud Build. Cloud Build tries to locate the repository path provided in the tag.\n",
    "\n",
    "Learn more about building and pushing a docker image with [Cloud Build](https://cloud.google.com/build/docs/build-push-docker-image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fb45b22c008"
   },
   "outputs": [],
   "source": [
    "! gcloud builds submit ./predictor \\\n",
    "--region={REGION} \\\n",
    "--tag=$CUSTOM_PREDICTOR_IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2c331bdaf370"
   },
   "source": [
    "### Deploy the serving container to Vertex AI\n",
    "\n",
    "Deploying a model to a Vertex AI Endpoint is necessary for making online predictions. This process involves creating a model resource in the Vertex AI Model Registry and deploying the model to the endpoint. The deployed model then runs a custom container image to serve predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the model and image to Vertex AI Model Registry\n",
    "\n",
    "Create a Vertex AI model resource with the created model artifacts and the container image in Vertex AI Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5a1472f735b"
   },
   "outputs": [],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    model_id=MODEL_ID,\n",
    "    description=MODEL_DESCRIPTION,\n",
    "    serving_container_image_uri=CUSTOM_PREDICTOR_IMAGE_URI,\n",
    "    serving_container_predict_route=PREDICT_ROUTE,\n",
    "    serving_container_health_route=HEALTH_ROUTE,\n",
    "    serving_container_ports=SERVING_CONTAINER_PORTS,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(\"Model display name: \", model.display_name)\n",
    "print(\"Model resource name: \",model.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7720d771633"
   },
   "source": [
    "#### Create a Vertex AI Endpoint\n",
    "\n",
    "Create a Vertex AI Endpoint to deploy the registered Vertex AI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fc8fe6b64dd1"
   },
   "outputs": [],
   "source": [
    "endpoint = aiplatform.Endpoint.create(display_name=ENDPOINT_DISPLAY_NAME)\n",
    "ENDPOINT_ID = endpoint.name\n",
    "\n",
    "print(\"Endpoint: \", endpoint)\n",
    "print(\"Endpoint ID: \", ENDPOINT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy the Model to Endpoint using Cloud Deploy\n",
    "\n",
    "[Cloud Deploy](https://cloud.google.com/deploy) makes continuous delivery of models easy by allowing users to define releases and progress them through environments such as test, stage, and production. It provides easy promotion, approval and rollback of releases. \n",
    "\n",
    "We can use Cloud Deploy to deploy the model to a target endpoint. The `build_and_register.sh` builds the Vertex AI model deployer image and registers a Cloud Deploy custom target type that references the image. The script executes these steps:\n",
    "* Define a custom action in the  file, which is similar to deploy hooks.\n",
    "* Define a custom target type, which is a Cloud Deploy resource identifying the custom action used by targets of this type.\n",
    "* Set up a target definition for a custom target, which is similar to any target type but includes additional properties.\n",
    "* Set up a Cloud Deploy delivery pipeline that references the configured target.\n",
    "\n",
    "Clone the Cloud Deploy samples repository, set the current directory to the vertex AI sample quickstart folder, then run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/googlecloudplatform/cloud-deploy-samples.git\n",
    "\n",
    "! cd cloud-deploy-samples/custom-targets/vertex-ai/quickstart\n",
    "\n",
    "! ../build_and_register.sh -p $PROJECT_ID -r $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the placeholders in the Cloud Deploy and Skaffold configuration values with the actual images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMPDIR=\"tmp\"\n",
    "\n",
    "! mkdir -p $TMPDIR\n",
    "\n",
    "! ./replace_variables.sh -p $PROJECT_ID -r $REGION -e $ENDPOINT_ID -t $TMPDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the Cloud Deploy configuration defined in `clouddeploy.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud deploy apply --file=$TMPDIR/clouddeploy.yaml --project=$PROJECT_ID --region=$REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a release and rollout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELEASE_NAME = \"release-0001\"\n",
    "DELIVERY_PIPELINE_NAME = \"vertex-ai-cloud-deploy-pipeline\"\n",
    "DEPLOY_PARAMS = f'customTarget/vertexAIModel=projects/{PROJECT_ID}/locations/{REGION}/models/{MODEL_ID}'\n",
    "\n",
    "! gcloud deploy releases create $RELEASE_NAME \\\n",
    "    --delivery-pipeline=$DELIVERY_PIPELINE_NAME \\\n",
    "    --project=$PROJECT_ID \\\n",
    "    --region=$REGION \\\n",
    "    --source=$TMPDIR/configuration \\\n",
    "    --deploy-parameters=$DEPLOY_PARAMS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitor the release's progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "! gcloud deploy releases describe $RELEASE_NAME \\\n",
    "    --delivery-pipeline=$DELIVERY_PIPELINE_NAME \\\n",
    "    --project=$PROJECT_ID \\\n",
    "    --region=$REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitor the rollout status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_NAME = \"prod-endpoint\"\n",
    "\n",
    "! gcloud deploy rollouts describe $(gcloud deploy targets describe $TARGET_NAME --delivery-pipeline=$DELIVERY_PIPELINE_NAME --region=$REGION --format=\"value('Latest rollout')\") \\\n",
    "    --release=$RELEASE_NAME \\\n",
    "    --delivery-pipeline=$DELIVERY_PIPELINE_NAME \\\n",
    "    --project=$PROJECT_ID \\\n",
    "    --region=$REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "094f7b4d8007"
   },
   "source": [
    "## Send online prediction requests\n",
    "\n",
    "Now, invoke the endpoint where the model is deployed using the Vertex AI SDK to make predictions for some test instances.\n",
    "\n",
    "### Define and format input for online prediction\n",
    "\n",
    "This notebook uses [TorchServe KServe](https://pytorch.org/serve/inference_api.html#kserve-inference-api) based inference API, which is also a Vertex AI predictions [compatible format](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#prediction). For online prediction requests, format the prediction input instances as JSON with base64 encoding as follows:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"data\": {\n",
    "            \"b64\": \"<base64 encoded string>\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5f0b7f8fc9a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_instances = [\n",
    "    b\"I went to a meeting that went really well.\",\n",
    "    b\"I ran four miles this morning with a good time.\",\n",
    "    b\"Watching the storms we had yesterday.  The lightning was incredible!\",\n",
    "    b\"The last night I said with her 'I love you '. And she said ' Yes'.\",\n",
    "    b\"I had followed a complex recipe making roasted duck, which took me hours and I had successfully made it.\",\n",
    "    b\"I woke up this morning to birds chirping.\",\n",
    "]\n",
    "\n",
    "formatted_test_instances = []\n",
    "for test_instance in test_instances:\n",
    "    b64_encoded = base64.b64encode(test_instance)\n",
    "    formated_test_instance = [{\"data\": {\"b64\": f\"{str(b64_encoded.decode('utf-8'))}\"}}]\n",
    "    formatted_test_instances.append(formated_test_instance)\n",
    "\n",
    "print(formatted_test_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0a24c94d66c"
   },
   "source": [
    "### Send online prediction requests\n",
    "\n",
    "Call prediction endpoint with formatted input requests and get the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "515acf48503c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(test_instances)):\n",
    "    test_instance = test_instances[i]\n",
    "    formatted_test_instance = formatted_test_instances[i]\n",
    "    prediction = endpoint.predict(instances=formatted_test_instance)\n",
    "    \n",
    "    print(f\"Input: \\n\\t{test_instance.decode('utf-8')}\\n\")\n",
    "    print(f\"Formatted Input: \\n{json.dumps(formated_test_instance, indent=4)}\\n\")\n",
    "    print(f\"Prediction Response: \\n\\t{prediction}\")\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "787f896a1daa"
   },
   "source": [
    "## Cleaning up \n",
    "\n",
    "To clean up all Google Cloud resources used in this notebook, you can [delete the Google Cloud project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "Otherwise, you can delete the individual resources you created in this tutorial:\n",
    "\n",
    "- Vertex AI Custom Training Job\n",
    "- Vertex AI Model\n",
    "- Vertex AI Endpoint\n",
    "- Cloud Storage Bucket\n",
    "- Artifact Registry Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdefede69285"
   },
   "outputs": [],
   "source": [
    "# Set to true if you want to delete the bucket\n",
    "delete_bucket = False\n",
    "\n",
    "# Delete the Custom training job\n",
    "job.delete()\n",
    "\n",
    "# Undeploy the model from the endpoint\n",
    "endpoint.undeploy_all()\n",
    "# Delete the endpoint\n",
    "endpoint.delete()\n",
    "\n",
    "# Delete the Vertex AI Model resource\n",
    "model.delete()\n",
    "\n",
    "# Delete the Cloud Storage bucket\n",
    "if delete_bucket:\n",
    "    ! gsutil -m rm -r $BUCKET_URI\n",
    "\n",
    "# Delete artifact repository\n",
    "! gcloud artifacts repositories delete $APP_NAME --location=$REGION --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "This notebook is inspired by the Hugging Face [Token Classification](https://github.com/huggingface/notebooks/blob/9d8acb94105649c03ad6ce1c7f702520100fc41b/examples/token_classification.ipynb), [Run Glue](https://github.com/huggingface/transformers/blob/fb560dcb075497f61880010245192e7e1fdbeca4/examples/run_glue.py), [Text Classification](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/39da99a8bbe57184199e79dcb58ef8dc23cf54ff/notebooks/official/training/pytorch-text-sentiment-classification-custom-train-deploy.ipynb), and [Vertex AI Model Deployer](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/39da99a8bbe57184199e79dcb58ef8dc23cf54ff/notebooks/community/model_registry/get_started_with_vertex_ai_deployer.ipynb) notebooks."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "pytorch-text-sentiment-classification-custom-train-deploy.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
